from langchain_huggingface import HuggingFaceEmbeddings  # âœ… Updated import
from langchain_chroma import Chroma  # âœ… Updated import
from config import CHROMA_DB_PATH, EMBEDDING_MODEL

# Load embeddings model
embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

# Load ChromaDB
db = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)


def retrieve_similar_chunks(query: str, k=5):
    """Retrieve top-k most relevant document chunks from ChromaDB with metadata."""
    
    results = db.similarity_search_with_score(query, k=k)  # âœ… Retrieves content + score
    
    retrieved_docs = [
        {
            "num": doc.metadata.get("num", "Unknown"),  # âœ… Retrieve stored 'num'
            "content": doc.page_content,
            "score": score  # âœ… Include similarity score
        }
        for doc, score in results
    ]
    
    return retrieved_docs


# Example usage
query = "artificial intelligence in movies"
top_chunks = retrieve_similar_chunks(query, k=5)

# Print results
for chunk in top_chunks:
    print(f"ğŸ“‚ File Num: {chunk['num']}\nğŸ” Similarity Score: {chunk['score']:.4f}\nğŸ“ Content: {chunk['content']}\n{'-'*80}")
